{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Clean and preprocess a research paper abstract for computational analysis to enhance searchability\n",
        "and data retrieval.\n",
        "Sample Text: \"Abstract—Genomic Sequence Data Analysis: With the advent of high-throughput\n",
        "sequencing technologies, vast amounts of genomic data have been generated. This paper discusses\n",
        "computational methods for sequence data analysis, focusing on algorithms and machine learning\n",
        "techniques. Visit our research portal for more information: www.genomeanalysis.net. Keywords:\n",
        "Genomics, Bioinformatics, Machine Learning, Sequencing. @Genome_Research\"\n",
        "Tasks:\n",
        "1. Cleaning Text Data:\n",
        "o Remove URLs, email addresses, hashtags, mentions, and keywords section.\n",
        "o Eliminate all punctuation and special characters.\n",
        "2. Lowercasing and Handling Non-Alphanumeric Characters:\n",
        "o Convert all text to lowercase.\n",
        "o Ensure that only spaces and alphanumeric characters remain.\n",
        "3. Tokenization:\n",
        "o Perform word and sentence tokenization using NLTK.\n",
        "4. Normalization Techniques:\n",
        "o Apply both Porter and Snowball Stemmers to the tokenized words.\n",
        "5. POS Tagging:\n",
        "o Conduct POS tagging on the cleaned and tokenized text using NLTK’s default POS\n",
        "tagger.\n",
        "Expected Outputs:\n",
        "• Cleaned Text: \"abstract genomic sequence data analysis with the advent of high throughput\n",
        "sequencing technologies vast amounts of genomic data have been generated this paper\n",
        "discusses computational methods for sequence data analysis focusing on algorithms and\n",
        "machine learning techniques\"\n",
        "• Word Tokenization (NLTK): ['abstract', 'genomic', 'sequence', 'data', 'analysis', 'with', 'the',\n",
        "'advent', 'of', 'high', 'throughput', 'sequencing', 'technologies', 'vast', 'amounts', 'of', 'genomic',\n",
        "'data', 'have', 'been', 'generated', 'this', 'paper', 'discusses', 'computational', 'methods', 'for',\n",
        "'sequence', 'data', 'analysis', 'focusing', 'on', 'algorithms', 'and', 'machine', 'learning', 'techniques']\n",
        "• Sentence Tokenization (NLTK): [\"abstract genomic sequence data analysis with the advent\n",
        "of high throughput sequencing technologies vast amounts of genomic data have been\n",
        "generated\", \"this paper discusses computational methods for sequence data analysis focusing\n",
        "on algorithms and machine learning techniques\"]\n",
        "• Stemming Output (Porter and Snowball): Similar stem outputs as the Snowball stemmer is\n",
        "slightly more aggressive but the difference will mainly show in handling complex scientific\n",
        "terms.\n",
        "• POS Tagging (NLTK): [('abstract', 'NN'), ('genomic', 'JJ'), ('sequence', 'NN'), ('data', 'NNS'),\n",
        "('analysis', 'NN'), ('with', 'IN'), ('the', 'DT'), ('advent', 'NN'), ('of', 'IN'), ('high', 'JJ'), ('throughput',\n",
        "'NN'), ('sequencing', 'NN'), ('technologies', 'NNS'), ('vast', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'),\n",
        "('genomic', 'JJ'), ('data', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('generated', 'VBN'), ('this',\n",
        "'DT'), ('paper', 'NN'), ('discusses', 'VBZ'), ('computational', 'JJ'), ('methods', 'NNS'), ('for', 'IN'),\n",
        "('sequence', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('focusing', 'VBG'), ('on', 'IN'), ('algorithms',\n",
        "'NNS'), ('and', 'CC'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS')]\n"
      ],
      "metadata": {
        "id": "wieP4KrZq6u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXl2LXmxrGgv",
        "outputId": "c254f8e9-a8fd-4a1d-ea25-df38709ae566"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T2bGxcPwq3eN"
      },
      "outputs": [],
      "source": [
        "# Sample abstract\n",
        "text = \"\"\"Abstract-Genomic Sequence Data Analysis: With the advent of high-throughput sequencing technologies,\n",
        "vast amounts of genomic data have been generated. This paper discusses computational methods for sequence data analysis,\n",
        "focusing on algorithms and machine learning techniques. Visit our research portal for more information: www.genomeanalysis.net.\n",
        "Keywords: Genomics, Bioinformatics, Machine Learning, Sequencing @Genome_Research\"\"\"\n",
        "\n",
        "#1 Cleaning the text\n",
        "text=text.lower()\n",
        "text = re.sub(r\"http\\S+|www\\S+|@\\S+|#\\S+\", \"\", text)  # Remove URLs, mentions, hashtags\n",
        "text = re.sub(r\"Keywords:.*\", \"\", text)  # Remove keywords section\n",
        "text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters and punctuation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Sentence Tokenization\n",
        "print(\"Sentence Tokenization:\")\n",
        "sentences = sent_tokenize(text)\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    print(f\"Sentence {i}: {sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGpPdwI1rVb9",
        "outputId": "a0ff98e2-23ba-4a0e-dc3c-ba8e23062c48"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokenization:\n",
            "Sentence 1: abstractgenomic sequence data analysis with the advent of highthroughput sequencing technologies \n",
            "vast amounts of genomic data have been generated this paper discusses computational methods for sequence data analysis \n",
            "focusing on algorithms and machine learning techniques visit our research portal for more information  \n",
            "keywords genomics bioinformatics machine learning sequencing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 word Tokenization\n",
        "print(\"\\nWord Tokenization:\")\n",
        "# Word Tokenization for each sentence\n",
        "for i, sentence in enumerate(sentences, 1):\n",
        "    words = word_tokenize(sentence)\n",
        "    print(f\"Words in Sentence {i}: {words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aOtMbeirg7h",
        "outputId": "fbf01977-0166-4ecb-dd19-63a7abe20e1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Tokenization:\n",
            "Words in Sentence 1: ['abstractgenomic', 'sequence', 'data', 'analysis', 'with', 'the', 'advent', 'of', 'highthroughput', 'sequencing', 'technologies', 'vast', 'amounts', 'of', 'genomic', 'data', 'have', 'been', 'generated', 'this', 'paper', 'discusses', 'computational', 'methods', 'for', 'sequence', 'data', 'analysis', 'focusing', 'on', 'algorithms', 'and', 'machine', 'learning', 'techniques', 'visit', 'our', 'research', 'portal', 'for', 'more', 'information', 'keywords', 'genomics', 'bioinformatics', 'machine', 'learning', 'sequencing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "words = word_tokenize(text)\n",
        "stemmed_words = [ps.stem(word) for word in words]\n",
        "print(\"Original Words:\", words)\n",
        "print(\"Stemmed Words:\", stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW8YlwT_rweO",
        "outputId": "19c019a1-d2ca-4279-9a45-4686ea4f146f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['abstractgenomic', 'sequence', 'data', 'analysis', 'with', 'the', 'advent', 'of', 'highthroughput', 'sequencing', 'technologies', 'vast', 'amounts', 'of', 'genomic', 'data', 'have', 'been', 'generated', 'this', 'paper', 'discusses', 'computational', 'methods', 'for', 'sequence', 'data', 'analysis', 'focusing', 'on', 'algorithms', 'and', 'machine', 'learning', 'techniques', 'visit', 'our', 'research', 'portal', 'for', 'more', 'information', 'keywords', 'genomics', 'bioinformatics', 'machine', 'learning', 'sequencing']\n",
            "Stemmed Words: ['abstractgenom', 'sequenc', 'data', 'analysi', 'with', 'the', 'advent', 'of', 'highthroughput', 'sequenc', 'technolog', 'vast', 'amount', 'of', 'genom', 'data', 'have', 'been', 'gener', 'thi', 'paper', 'discuss', 'comput', 'method', 'for', 'sequenc', 'data', 'analysi', 'focus', 'on', 'algorithm', 'and', 'machin', 'learn', 'techniqu', 'visit', 'our', 'research', 'portal', 'for', 'more', 'inform', 'keyword', 'genom', 'bioinformat', 'machin', 'learn', 'sequenc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(\"Original Words:\", words)\n",
        "print(\"Stemmed Words:\", stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8_X8XhgsGG5",
        "outputId": "4263774f-aafc-4cec-a666-0d1c826ec5c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Words: ['abstractgenomic', 'sequence', 'data', 'analysis', 'with', 'the', 'advent', 'of', 'highthroughput', 'sequencing', 'technologies', 'vast', 'amounts', 'of', 'genomic', 'data', 'have', 'been', 'generated', 'this', 'paper', 'discusses', 'computational', 'methods', 'for', 'sequence', 'data', 'analysis', 'focusing', 'on', 'algorithms', 'and', 'machine', 'learning', 'techniques', 'visit', 'our', 'research', 'portal', 'for', 'more', 'information', 'keywords', 'genomics', 'bioinformatics', 'machine', 'learning', 'sequencing']\n",
            "Stemmed Words: ['abstractgenom', 'sequenc', 'data', 'analysi', 'with', 'the', 'advent', 'of', 'highthroughput', 'sequenc', 'technolog', 'vast', 'amount', 'of', 'genom', 'data', 'have', 'been', 'generat', 'this', 'paper', 'discuss', 'comput', 'method', 'for', 'sequenc', 'data', 'analysi', 'focus', 'on', 'algorithm', 'and', 'machin', 'learn', 'techniqu', 'visit', 'our', 'research', 'portal', 'for', 'more', 'inform', 'keyword', 'genom', 'bioinformat', 'machin', 'learn', 'sequenc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5 POS Tagging\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "tokens = word_tokenize(sentence)\n",
        "tagged = pos_tag(tokens)\n",
        "print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMSxvPV6rP4J",
        "outputId": "3db83076-3475-4d9f-b310-5c74a0976900"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('abstractgenomic', 'JJ'), ('sequence', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('with', 'IN'), ('the', 'DT'), ('advent', 'NN'), ('of', 'IN'), ('highthroughput', 'NN'), ('sequencing', 'VBG'), ('technologies', 'NNS'), ('vast', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('genomic', 'JJ'), ('data', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('generated', 'VBN'), ('this', 'DT'), ('paper', 'NN'), ('discusses', 'VBZ'), ('computational', 'JJ'), ('methods', 'NNS'), ('for', 'IN'), ('sequence', 'NN'), ('data', 'NNS'), ('analysis', 'NN'), ('focusing', 'VBG'), ('on', 'IN'), ('algorithms', 'NN'), ('and', 'CC'), ('machine', 'NN'), ('learning', 'VBG'), ('techniques', 'NNS'), ('visit', 'VB'), ('our', 'PRP$'), ('research', 'NN'), ('portal', 'NN'), ('for', 'IN'), ('more', 'JJR'), ('information', 'NN'), ('keywords', 'NNS'), ('genomics', 'NNS'), ('bioinformatics', 'NNS'), ('machine', 'NN'), ('learning', 'VBG'), ('sequencing', 'VBG')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}